Welcome to Unify!
=================

Unify is your centralized platform for LLM endpoints. If you‚Äôre using or planning to use an LLM in your application or service, Unify lets you:

* **üîë Use any endpoint with one key**: You only need a Unify API Key to access the latest LLMs through any endpoint provider. Each model has a unfied API that enables seamless provider switching without needing to refactor.

* **üöÄ Route to the best endpoints**: Each prompt is assessed separately and sent to the endpoint(s) that will (a) return the best response, and (b) yield the best performance for a target metric of your choice, including high-throughput, low cost or low latency.

* **‚öñÔ∏è Benchmark endpoint performance**: Our live, dynamic benchmarks let you objectively compare endpoints speed, latency and costs; to make informed decisions when selecting the model or provider that fits your needs.

.. note::
    You will soon be able to customize the routing and benchmarks on your own datasets. If you'd like to try it out already, feel free to `reach out to us <https://calendly.com/daniel-lenton/beta-discussion>`_.

Getting Started
---------------

To start querying our endpoints, first generate a Unify API key by :code:`Signing Up` through the `Unify Console <https://console.unify.ai/>`_ . 

We recommend you go through out `walkthrough <https://unify.ai/docs/hub/home/walkthrough.html>`_ to discover how to use the console. If you'd like to jump to coding, let's see how you can `make your first request! <https://unify.ai/docs/hub/home/make_your_first_request.html>`_



.. note::
    If you encounter any issue, have any suggestion, feature you'd like to see, or anything you think can be improved please get in touch with us on
    `Discord <https://discord.com/invite/sXyFF8tDtm>`_ or via :code:`hub@unify.ai`