{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Gp0FAI1Zkbxw"
      },
      "source": [
        "### Build a ChatBot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1QFiUcdR-aJ"
      },
      "source": [
        "In this notebook, we will build an interactive chatbot using the `unifyai` python package.\n",
        "\n",
        "Under the hood, chatbots are very simple to implement. All LLM endpoints are stateless, and therefore the entire conversation history is repeatedly fed as input to the model. All that is required of the local agent is to store this history, and correctly pass it to the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdCA_YoYQ-X8"
      },
      "source": [
        "#### Install Dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HS2xRFiNPSiL"
      },
      "source": [
        "To run this notebook, you will need to install the `unifyai` [python package](https://pypi.org/project/unifyai/). You can do so by running the cell below ⬇️"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MqRVTcHgWhl",
        "outputId": "dbae7a55-ecad-478c-bd57-c0ecdb0eaeaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting unifyai==0.8.1\n",
            "  Downloading unifyai-0.8.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from unifyai==0.8.1) (1.17.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from unifyai==0.8.1) (2.31.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.12.0->unifyai==0.8.1) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.12.0->unifyai==0.8.1) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.12.0->unifyai==0.8.1) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.12.0->unifyai==0.8.1) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.12.0->unifyai==0.8.1) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.12.0->unifyai==0.8.1) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.12.0->unifyai==0.8.1) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->unifyai==0.8.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->unifyai==0.8.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->unifyai==0.8.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->unifyai==0.8.1) (2024.2.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.12.0->unifyai==0.8.1) (1.2.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.12.0->unifyai==0.8.1) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.12.0->unifyai==0.8.1) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai<2.0.0,>=1.12.0->unifyai==0.8.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai<2.0.0,>=1.12.0->unifyai==0.8.1) (2.16.3)\n",
            "Installing collected packages: unifyai\n",
            "  Attempting uninstall: unifyai\n",
            "    Found existing installation: unifyai 0.8.0\n",
            "    Uninstalling unifyai-0.8.0:\n",
            "      Successfully uninstalled unifyai-0.8.0\n",
            "Successfully installed unifyai-0.8.1\n"
          ]
        }
      ],
      "source": [
        "!pip install unifyai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhgBuOhzRFeE"
      },
      "source": [
        "#### The Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yX6plilUlGYl"
      },
      "source": [
        "We define a simple chatbot class below, with the only public function being `run`. Before starting, you should to obtain a UNIFY key from the [console page](https://console.unify.ai/login?callbackUrl=%2F) and assign it to the `UNIFY_KEY` variable below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feMwwdteRuOL"
      },
      "outputs": [],
      "source": [
        "UNIFY_KEY = #ENTERUNIFYKEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGGw4tDagqV5"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "from typing import Optional\n",
        "from unify import Unify\n",
        "\n",
        "\n",
        "class ChatBot:\n",
        "    \"\"\"Agent class represents an LLM chat agent.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        api_key: Optional[str] = None,\n",
        "        endpoint: Optional[str] = None,\n",
        "        model: Optional[str] = None,\n",
        "        provider: Optional[str] = None,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Initializes the ChatBot object.\n",
        "\n",
        "        Args:\n",
        "            api_key (str, optional): API key for accessing the Unify API.\n",
        "                If None, it attempts to retrieve the API key from the\n",
        "                environment variable UNIFY_KEY.\n",
        "                Defaults to None.\n",
        "\n",
        "            endpoint (str, optional): Endpoint name in OpenAI API format:\n",
        "                <uploaded_by>/<model_name>@<provider_name>\n",
        "                Defaults to None.\n",
        "\n",
        "            model (str, optional): Name of the model. If None,\n",
        "            endpoint must be provided.\n",
        "\n",
        "            provider (str, optional): Name of the provider. If None,\n",
        "            endpoint must be provided.\n",
        "        Raises:\n",
        "            UnifyError: If the API key is missing.\n",
        "        \"\"\"\n",
        "        self._message_history = []\n",
        "        self._paused = False\n",
        "        self._client = Unify(\n",
        "            api_key=api_key,\n",
        "            endpoint=endpoint,\n",
        "            model=model,\n",
        "            provider=provider,\n",
        "        )\n",
        "\n",
        "    @property\n",
        "    def client(self) -> str:\n",
        "        \"\"\"\n",
        "        Get the client object.\n",
        "\n",
        "        Returns:\n",
        "            str: The model name.\n",
        "        \"\"\"\n",
        "        return self._client\n",
        "\n",
        "    def set_client(self, value: Unify) -> None:\n",
        "        \"\"\"\n",
        "        Set the model name.\n",
        "\n",
        "        Args:\n",
        "            value: The unify client.\n",
        "        \"\"\"\n",
        "        self._client = value\n",
        "\n",
        "    @property\n",
        "    def model(self) -> str:\n",
        "        \"\"\"\n",
        "        Get the model name.\n",
        "\n",
        "        Returns:\n",
        "            str: The model name.\n",
        "        \"\"\"\n",
        "        return self._client.model\n",
        "\n",
        "    def set_model(self, value: str) -> None:\n",
        "        \"\"\"\n",
        "        Set the model name.\n",
        "\n",
        "        Args:\n",
        "            value (str): The model name.\n",
        "        \"\"\"\n",
        "        self._client.set_model(value)\n",
        "        if self._client.provider:\n",
        "            self._client.set_endpoint(\"@\".join([value, self._client.provider]))\n",
        "        else:\n",
        "            mode = self._client.endpoint.split(\"@\")[1]\n",
        "            self._client.set_endpoint(\"@\".join([value, mode]))\n",
        "\n",
        "    @property\n",
        "    def provider(self) -> Optional[str]:\n",
        "        \"\"\"\n",
        "        Get the provider name.\n",
        "\n",
        "        Returns:\n",
        "            str: The provider name.\n",
        "        \"\"\"\n",
        "        return self._client.provider\n",
        "\n",
        "    def set_provider(self, value: str) -> None:\n",
        "        \"\"\"\n",
        "        Set the provider name.\n",
        "\n",
        "        Args:\n",
        "            value (str): The provider name.\n",
        "        \"\"\"\n",
        "        self._client.set_provider(value)\n",
        "        self._client.set_endpoint(\"@\".join([self._model, value]))\n",
        "\n",
        "    @property\n",
        "    def endpoint(self) -> str:\n",
        "        \"\"\"\n",
        "        Get the endpoint name.\n",
        "\n",
        "        Returns:\n",
        "            str: The endpoint name.\n",
        "        \"\"\"\n",
        "        return self._client.endpoint\n",
        "\n",
        "    def set_endpoint(self, value: str) -> None:\n",
        "        \"\"\"\n",
        "        Set the model name.\n",
        "\n",
        "        Args:\n",
        "            value (str): The endpoint name.\n",
        "        \"\"\"\n",
        "        self._client.set_endpoint(value)\n",
        "        self._client.set_model(value.split(\"@\")[0])\n",
        "        self._client.set_provider(value.split(\"@\")[1])\n",
        "\n",
        "    def _get_credits(self):\n",
        "        \"\"\"\n",
        "        Retrieves the current credit balance from associated with the UNIFY account.\n",
        "\n",
        "        Returns:\n",
        "            float: Current credit balance.\n",
        "        \"\"\"\n",
        "        return self._client.get_credit_balance()\n",
        "\n",
        "    def _process_input(self, inp: str, show_credits: bool, show_provider: bool):\n",
        "        \"\"\"\n",
        "        Processes the user input to generate AI response.\n",
        "\n",
        "        Args:\n",
        "            inp (str): User input message.\n",
        "            show_credits (bool): Whether to show credit consumption.\n",
        "            show_credits (bool): Whether to show provider used.\n",
        "\n",
        "        Yields:\n",
        "            str: Generated AI response chunks.\n",
        "        \"\"\"\n",
        "        self._update_message_history(role=\"user\", content=inp)\n",
        "        initial_credit_balance = self._get_credits()\n",
        "        stream = self._client.generate(\n",
        "            messages=self._message_history,\n",
        "            stream=True,\n",
        "        )\n",
        "        words = \"\"\n",
        "        for chunk in stream:\n",
        "            words += chunk\n",
        "            yield chunk\n",
        "\n",
        "        self._update_message_history(\n",
        "            role=\"assistant\",\n",
        "            content=words,\n",
        "        )\n",
        "        final_credit_balance = self._get_credits()\n",
        "        if show_credits:\n",
        "            sys.stdout.write(\n",
        "                \"\\n(spent {:.6f} credits)\".format(\n",
        "                    initial_credit_balance - final_credit_balance,\n",
        "                ),\n",
        "            )\n",
        "        if show_provider:\n",
        "            sys.stdout.write(\"\\n(provider: {})\".format(self._client.provider))\n",
        "\n",
        "    def _update_message_history(self, role: str, content: str):\n",
        "        \"\"\"\n",
        "        Updates message history with user input.\n",
        "\n",
        "        Args:\n",
        "            role (str): Either \"assistant\" or \"user\".\n",
        "            content (str): User input message.\n",
        "        \"\"\"\n",
        "        self._message_history.append(\n",
        "            {\n",
        "                \"role\": role,\n",
        "                \"content\": content,\n",
        "            },\n",
        "        )\n",
        "\n",
        "    def clear_chat_history(self):\n",
        "        \"\"\"Clears the chat history.\"\"\"\n",
        "        self._message_history.clear()\n",
        "\n",
        "    def run(self, show_credits: bool = False, show_provider: bool = False):\n",
        "        \"\"\"\n",
        "        Starts the chat interaction loop.\n",
        "\n",
        "        Args:\n",
        "            show_credits (bool, optional): Whether to show credit consumption.\n",
        "            Defaults to False.\n",
        "            show_provider (bool, optional): Whether to show the provider used.\n",
        "            Defaults to False.\n",
        "        \"\"\"\n",
        "        if not self._paused:\n",
        "            sys.stdout.write(\n",
        "                \"Let's have a chat. (Enter `pause` to pause and `quit` to exit)\\n\",\n",
        "            )\n",
        "            self.clear_chat_history()\n",
        "        else:\n",
        "            sys.stdout.write(\n",
        "                \"Welcome back! (Remember, enter `pause` to pause and `quit` to exit)\\n\",\n",
        "            )\n",
        "        self._paused = False\n",
        "        while True:\n",
        "            sys.stdout.write(\"> \")\n",
        "            inp = input()\n",
        "            if inp == \"quit\":\n",
        "                self.clear_chat_history()\n",
        "                break\n",
        "            elif inp == \"pause\":\n",
        "                self._paused = True\n",
        "                break\n",
        "            for word in self._process_input(inp, show_credits, show_provider):\n",
        "                sys.stdout.write(word)\n",
        "                sys.stdout.flush()\n",
        "            sys.stdout.write(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Swnehb9Rvdh"
      },
      "source": [
        "#### Let's Chat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qrsyr6gZmGFs"
      },
      "source": [
        "Now, we can instantiate and chat with this agent. For this demo, we'll utilize the `llama-2-7b-chat` model from `anyscale`. However, you have the flexibility to select any model and provider from our supported options on the [benchmarks interface](https://unify.ai/hub)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b25iLp5nOPxQ",
        "outputId": "a1f6c38f-9774-4544-e761-2ba667eba787"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Let's have a chat. (Enter `pause` to pause and `quit` to exit)\n",
            ">  Hi, nice to meet you. My name is Foo Barrymore, and I am 25 years old.\n",
            "  Hello Foo! Nice to meet you too. I'm just an AI, I don't have a personal name, but I'm here to help you with any questions or concerns you might have. How has your day been so far?\n",
            "> How old am I?\n",
            "  You've told me that you're 25 years old. Is there anything else you'd like to know or discuss?\n",
            "> Your memory is astounding\n",
            "  Thank you! I'm glad you think so. I'm designed to remember and process large amounts of information, and I'm constantly learning and improving my abilities. However, it's important to note that my memory is not perfect, and there may be times when I forget or misremember certain details. If you have any specific questions or concerns about my memory or abilities, feel free to ask!\n",
            "> quit\n"
          ]
        }
      ],
      "source": [
        "agent = ChatBot(api_key = UNIFY_KEY, endpoint = \"llama-2-70b-chat@anyscale\")\n",
        "agent.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxK6r9yrnfUS"
      },
      "source": [
        "You can also see how many credits your prompt used. This option is set in the constructor, but it can be overwritten during the run command. When enabled, each response from the chatbot will then be appended with the credits spent:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8y34VMGnI93",
        "outputId": "b5d46d0c-72a5-4b17-81a8-e78188eb835e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Let's have a chat. (Enter `pause` to pause and `quit` to exit)\n",
            "> What is the capital of Palestine?\n",
            "  The question of the capital of Palestine is a politically sensitive and complex issue. The status of Jerusalem is disputed between Israelis and Palestinians, with both sides claiming it as their capital.\n",
            "\n",
            "The Palestinian National Authority, which governs the Palestinian territories in the West Bank and Gaza Strip, has its administrative center in Ramallah, which is often referred to as the \"de facto capital\" of Palestine. However, the Palestinian Authority has not declared a capital city, and the issue remains a matter of debate and negotiation in the Israeli-Palestinian peace process.\n",
            "\n",
            "The international community has not recognized any capital of Palestine, and many countries maintain their diplomatic missions to the Palestinian Authority in Tel Aviv, Israel, rather than in Ramallah or East Jerusalem, which is claimed by the Palestinians as the capital of a future Palestinian state.\n",
            "\n",
            "It is important to note that the issue of the capital of Palestine is closely tied to the broader conflict between Israelis and Palestinians, and any resolution to the conflict will need to address this issue in a way that is acceptable to both sides.\n",
            "(spent 0.000274 credits)\n",
            "> quit\n"
          ]
        }
      ],
      "source": [
        "agent.run(show_credits=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yc_rSlnroeWK"
      },
      "source": [
        "Finally, you can switch providers half-way through the conversation easily. This can be useful to handle prompt of varying complexity.\n",
        "\n",
        "For example we can start with a small model for answering simple questions, such as recalling facts, and then move to a larger model for a more complex task, such as creative writing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0N9GeB9KnrX-",
        "outputId": "ae913b2c-2bbf-4ff9-f9b6-fa98ae376c13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Let's have a chat. (Enter `pause` to pause and `quit` to exit)\n",
            "> What is the capital of Portugal?\n",
            "  The capital of Portugal is Lisbon (Portuguese: Lisboa).\n",
            "(spent 0.000032 credits)\n",
            "> My name is José Mourinho.\n",
            "  Ah, I see! José Mourinho is a well-known Portuguese football manager and former football player. He has managed several top-level clubs, including Chelsea, Inter Milan, Real Madrid, and Manchester United. Mourinho is known for his tactical approach to football and his ability to motivate his players. He has won numerous honors and awards throughout his career, including several league titles, domestic cups, and European championships. Is there anything else you'd like to know about José Mourinho?\n",
            "(spent 0.000159 credits)\n",
            "> pause\n"
          ]
        }
      ],
      "source": [
        "agent = ChatBot(api_key = UNIFY_KEY, endpoint = \"llama-2-70b-chat@anyscale\")\n",
        "agent.run(show_credits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQnQFGf0qxTE",
        "outputId": "24632ab9-8dff-414f-ab4d-cc57b444989e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome back! (Remember, enter `pause` to pause and `quit` to exit)\n",
            "> Please write me a poem about my life in Lisbon, using my name in the poem.\n",
            "In Lisbon's embrace, where tales intertwine,\n",
            "Lives José Mourinho, beneath the sun's fine shine.\n",
            "From cobblestone streets where echoes dance,\n",
            "To the Tagus' gentle waves that entrance.\n",
            "\n",
            "In youth, he dreamt beneath Iberian skies,\n",
            "Where passion is fierce and ambition never dies.\n",
            "With a ball at his feet and dreams in his heart,\n",
            "In Lisbon's grand story, he crafted his part.\n",
            "\n",
            "Eduardo VII Park, in the spring's embrace,\n",
            "Where thoughts of tactics first took place.\n",
            "Through Alfama's alleys, past Fado's mournful sound,\n",
            "Mourinho's purpose, in football, was found.\n",
            "\n",
            "From Benfica's nest to União de Leiria's helm,\n",
            "His journey began, in a realm\n",
            "Where strategies and plays, meticulously spun,\n",
            "Foreshadowed the triumphs that would be won.\n",
            "\n",
            "In Estádio da Luz, where eagles soar,\n",
            "Mourinho pondered scores and more.\n",
            "Though his stay was brief, the impact was deep;\n",
            "In Lisbon's lore, his legacy would steep.\n",
            "\n",
            "The boy from Setúbal, with Lisbon in his tale,\n",
            "Set forth to conquer, to win, and to prevail.\n",
            "Through Porto, London, Milan, Madrid's grand stage,\n",
            "His story was written, page by page.\n",
            "\n",
            "Yet, amidst the victories and the fame's bright light,\n",
            "In his heart, Lisbon remains, ever so bright.\n",
            "For it's there José Mourinho's dreams took flight,\n",
            "In Lisbon's embrace, under the starry night.\n",
            "\n",
            "So, here's to Mourinho, with Lisbon's spirit in his veins,\n",
            "Where the love for the game forever remains.\n",
            "In every triumph, in every fall,\n",
            "Lisbon, his beginning, the most cherished of all.\n",
            "(spent 0.012020 credits)\n",
            "> quit\n"
          ]
        }
      ],
      "source": [
        "agent.set_endpoint(\"gpt-4-turbo@openai\")\n",
        "agent.run(show_credits=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQ0AqGSvrTaP"
      },
      "source": [
        "Switching between providers mid-conversation makes it much easier to maximize quality and runtime performance based on the latest metrics, and also save on costs!\n",
        "\n",
        "In fact, you can automatically optimize for a metric of your choice with our [dynamic routing modes](https://unify.ai/docs/hub/concepts/runtime_routing.html#available-modes). For example, you can optimize for speed as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4W-35vbrFDP",
        "outputId": "6065088a-b79d-4ab7-96d5-7dd1cfc67ccf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Let's have a chat. (Enter `pause` to pause and `quit` to exit)\n",
            "> Tell me your favorite physics fact.\n",
            "My favorite physics fact is that the universe is still expanding! This means that the galaxies that are currently moving away from us will continue to move away from us, and eventually, they will move faster than the speed of light. This is known as the \"dark energy\" that is thought to be responsible for the acceleration of the universe's expansion.\n",
            "\n",
            "I find this fascinating because it shows that the universe is still evolving and changing, and there is still so much to learn about it. It's mind-boggling to think about the vastness of space and the mysteries that it holds.\n",
            "\n",
            "Additionally, this fact also reminds me of the importance of continuous learning and exploration. There is always more to discover and understand, and it's important to have a curious and open-minded approach to life.\n",
            "\n",
            "I hope this fact inspires you to learn more about the wonders of the universe!\n",
            "(provider: fireworks-ai)\n",
            "> quit\n"
          ]
        }
      ],
      "source": [
        "agent.set_endpoint(\"llama-2-70b-chat@highest-tks-per-sec\")\n",
        "agent.run(show_provider=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqSzrxL9WydO"
      },
      "source": [
        "The flag `show_provider` ensures that the specific provider is printed at the end of each response. For example, sometimes `anyscale` might be the fastest, and at other times it might be `together-ai` or `fireworks-ai`. This flag enables you to keep track of what provider is being used under the hood."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RM1uIFFaG9Gj"
      },
      "source": [
        "If the task is to summarize a document or your chat history grows, typically the input-cost becomes the primary cost driver. You can use our `lowest-input-cost` mode to direct queries to the provider with the lowest input cost automatically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1SG4s7BIpmR",
        "outputId": "18a2f091-3dc9-4065-c475-85c4b32e2bac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Let's have a chat. (Enter `pause` to pause and `quit` to exit)\n",
            "> Summarize the following in less than 10 words: Sir Isaac Newton FRS (25 December 1642 – 20 March 1726/27[a]) was an English polymath active as a mathematician, physicist, astronomer, alchemist, theologian, and author who was described in his time as a natural philosopher.[7] He was a key figure in the Scientific Revolution and the Enlightenment that followed. His pioneering book Philosophiæ Naturalis Principia Mathematica (Mathematical Principles of Natural Philosophy), first published in 1687, consolidated many previous results and established classical mechanics.[8][9] Newton also made seminal contributions to optics, and shares credit with German mathematician Gottfried Wilhelm Leibniz for developing infinitesimal calculus, though he developed calculus years before Leibniz.[10][11]  In the Principia, Newton formulated the laws of motion and universal gravitation that formed the dominant scientific viewpoint for centuries until it was superseded by the theory of relativity. Newton used his mathematical description of gravity to derive Kepler's laws of planetary motion, account for tides, the trajectories of comets, the precession of the equinoxes and other phenomena, eradicating doubt about the Solar System's heliocentricity.[12] He demonstrated that the motion of objects on Earth and celestial bodies could be accounted for by the same principles. Newton's inference that the Earth is an oblate spheroid was later confirmed by the geodetic measurements of Maupertuis, La Condamine, and others, convincing most European scientists of the superiority of Newtonian mechanics over earlier systems.  Newton built the first practical reflecting telescope and developed a sophisticated theory of colour based on the observation that a prism separates white light into the colours of the visible spectrum. His work on light was collected in his highly influential book Opticks, published in 1704. He also formulated an empirical law of cooling, made the first theoretical calculation of the speed of sound, and introduced the notion of a Newtonian fluid. In addition to his work on calculus, as a mathematician Newton contributed to the study of power series, generalised the binomial theorem to non-integer exponents, developed a method for approximating the roots of a function, and classified most of the cubic plane curves.  Newton was a fellow of Trinity College and the second Lucasian Professor of Mathematics at the University of Cambridge. He was a devout but unorthodox Christian who privately rejected the doctrine of the Trinity. He refused to take holy orders in the Church of England, unlike most members of the Cambridge faculty of the day. Beyond his work on the mathematical sciences, Newton dedicated much of his time to the study of alchemy and biblical chronology, but most of his work in those areas remained unpublished until long after his death. Politically and personally tied to the Whig party, Newton served two brief terms as Member of Parliament for the University of Cambridge, in 1689–1690 and 1701–1702. He was knighted by Queen Anne in 1705 and spent the last three decades of his life in London, serving as Warden (1696–1699) and Master (1699–1727) of the Royal Mint, as well as president of the Royal Society (1703–1727).\n",
            "  Newton: polymath, mathematician, physicist, astronomer, alchemist, theologian, and author.\n",
            "(provider: octoai)\n",
            "> quit\n"
          ]
        }
      ],
      "source": [
        "agent = ChatBot(api_key=UNIFY_KEY, endpoint=\"llama-2-70b-chat@lowest-input-cost\")\n",
        "agent.run(show_provider=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "W-EaEPxAKdKe"
      },
      "source": [
        "#### Python Package"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9vhGX9aKncg"
      },
      "source": [
        "The python package already contains the `ChatBot` agent and you may use it directly as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "en7GCev9KmgX",
        "outputId": "fcaa2b15-88a1-4108-e68e-a95b4c403302"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Let's have a chat. (Enter `pause` to pause and `quit` to exit)\n",
            "> Hey! How's it going?\n",
            "  Hello! I'm doing well, thank you for asking! It's going great here, just busy with various tasks and learning new things. However, I must point out that this conversation is a bit unusual as I'm just an AI and don't have personal experiences or emotions like humans do. I'm here to help answer any questions you may have, so feel free to ask me anything!\n",
            "> quit\n"
          ]
        }
      ],
      "source": [
        "from unify import ChatBot\n",
        "chatbot = ChatBot(api_key = UNIFY_KEY, endpoint=\"llama-2-7b-chat@anyscale\")\n",
        "chatbot.run()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nyq473oLxjoh"
      },
      "source": [
        "### Round Up\n",
        " Congratulations! 🚀 You are now capable of building ChatBot Agents for your application using our LLM endpoints. If you're a contributor and want to earn a cool badge, you should fill out this [form](https://docs.google.com/forms/d/e/1FAIpQLSdTd0U5czFNY3aNFHHbjizd4a9gz-oTINMrHMnopOgZzajs9g/viewform?usp=sf_link) which contains a few quiz questions about the concepts you learnt in this tutorial. Happy quizzing!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "1Swnehb9Rvdh"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
